{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8320b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/shared/3/projects/citation-context/s2orc/abstract_parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485ca8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "/dev/sda1        44T   43T  983G  98% /shared/3\r\n"
     ]
    }
   ],
   "source": [
    "!df -h /shared/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8185cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23G\t/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_0_processed_merged_01.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh /shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_0_processed_merged_01.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6332793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_paper_and_citation_all.tsv\t\t   s2orc_20_processed_merged_01.tsv\r\n",
      "df_paper_and_citation_background_end.tsv   s2orc_21_processed_merged_01.tsv\r\n",
      "df_paper_and_citation.tsv\t\t   s2orc_22_processed_merged_01.tsv\r\n",
      "s2orc_0_processed_merged_01_ims_added.tsv  s2orc_23_processed_merged_01.tsv\r\n",
      "s2orc_0_processed_merged_01.tsv\t\t   s2orc_24_processed_merged_01.tsv\r\n",
      "s2orc_10_processed_merged_01.tsv\t   s2orc_25_processed_merged_01.tsv\r\n",
      "s2orc_11_processed_merged_01.tsv\t   s2orc_26_processed_merged_01.tsv\r\n",
      "s2orc_12_processed_merged_01.tsv\t   s2orc_2_processed_merged_01.tsv\r\n",
      "s2orc_13_processed_merged_01.tsv\t   s2orc_3_processed_merged_01.tsv\r\n",
      "s2orc_14_processed_merged_01.tsv\t   s2orc_4_processed_merged_01.tsv\r\n",
      "s2orc_15_processed_merged_01.tsv\t   s2orc_5_processed_merged_01.tsv\r\n",
      "s2orc_16_processed_merged_01.tsv\t   s2orc_6_processed_merged_01.tsv\r\n",
      "s2orc_17_processed_merged_01.tsv\t   s2orc_7_processed_merged_01.tsv\r\n",
      "s2orc_18_processed_merged_01.tsv\t   s2orc_8_processed_merged_01.tsv\r\n",
      "s2orc_19_processed_merged_01.tsv\t   s2orc_9_processed_merged_01.tsv\r\n",
      "s2orc_1_processed_merged_01.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /shared/3/projects/citation-context/s2orc/s2orc_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98fe3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm /shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_17_processed_merged_01_ims_added.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c90fb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f99478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_0_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_17_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_19_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_21_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_23_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_25_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_1_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_2_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_3_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_4_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_5_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_6_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_7_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_8_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_9_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_10_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_11_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_12_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_13_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_14_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_15_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_16_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_18_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_20_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_22_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_24_processed_merged_01.tsv',\n",
       " '/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_26_processed_merged_01.tsv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "INPUT_DIR = '/shared/3/projects/citation-context/s2orc/s2orc_merge'\n",
    "INPUT_FILE_LIST = glob.glob(os.path.join(INPUT_DIR, \"s2orc_*_merged_01.tsv\"))\n",
    "INPUT_FILE_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5660361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citingcorpusid</th>\n",
       "      <th>citedcorpusid</th>\n",
       "      <th>context</th>\n",
       "      <th>context_count</th>\n",
       "      <th>intent</th>\n",
       "      <th>corpusid_from_citing</th>\n",
       "      <th>year_from_citing</th>\n",
       "      <th>citationcount_from_citing</th>\n",
       "      <th>fieldsofstudy_s2_from_citing</th>\n",
       "      <th>authorId_list_from_citing</th>\n",
       "      <th>...</th>\n",
       "      <th>citationcount_from_cited</th>\n",
       "      <th>fieldsofstudy_s2_from_cited</th>\n",
       "      <th>authorId_list_from_cited</th>\n",
       "      <th>fieldsofstudy_s2_from_cited_one</th>\n",
       "      <th>fieldsofstudy_s2_from_citing_one</th>\n",
       "      <th>team_size</th>\n",
       "      <th>if_background</th>\n",
       "      <th>if_end_citation</th>\n",
       "      <th>corpusid</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2381348</td>\n",
       "      <td>2019777.0</td>\n",
       "      <td>MIMO relay channels are studied in terms of er...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>2381348.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>33</td>\n",
       "      <td>['Business', 'Computer Science']</td>\n",
       "      <td>['39986350', '145142172']</td>\n",
       "      <td>...</td>\n",
       "      <td>283</td>\n",
       "      <td>['Computer Science']</td>\n",
       "      <td>['144545126', '1701637']</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Business</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019777</td>\n",
       "      <td>['\\nOptimal Space-Time Codes for the MIMO Ampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1505556</td>\n",
       "      <td>2019777.0</td>\n",
       "      <td>The DMT tradeoffs have been extensively studie...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>1505556.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>['Computer Science']</td>\n",
       "      <td>['2327626', '1688531', '47197693']</td>\n",
       "      <td>...</td>\n",
       "      <td>283</td>\n",
       "      <td>['Computer Science']</td>\n",
       "      <td>['144545126', '1701637']</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019777</td>\n",
       "      <td>['\\nOptimal Space-Time Codes for the MIMO Ampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1505556</td>\n",
       "      <td>2019777.0</td>\n",
       "      <td>Optimal codes for this setting exist for all v...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>1505556.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>22</td>\n",
       "      <td>['Computer Science']</td>\n",
       "      <td>['2327626', '1688531', '47197693']</td>\n",
       "      <td>...</td>\n",
       "      <td>283</td>\n",
       "      <td>['Computer Science']</td>\n",
       "      <td>['144545126', '1701637']</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019777</td>\n",
       "      <td>['\\nOptimal Space-Time Codes for the MIMO Ampl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   citingcorpusid  citedcorpusid  \\\n",
       "0         2381348      2019777.0   \n",
       "1         1505556      2019777.0   \n",
       "2         1505556      2019777.0   \n",
       "\n",
       "                                             context  context_count  \\\n",
       "0  MIMO relay channels are studied in terms of er...            1.0   \n",
       "1  The DMT tradeoffs have been extensively studie...            2.0   \n",
       "2  Optimal codes for this setting exist for all v...            2.0   \n",
       "\n",
       "           intent  corpusid_from_citing  year_from_citing  \\\n",
       "0  ['background']             2381348.0              2008   \n",
       "1  ['background']             1505556.0              2008   \n",
       "2  ['background']             1505556.0              2008   \n",
       "\n",
       "   citationcount_from_citing      fieldsofstudy_s2_from_citing  \\\n",
       "0                         33  ['Business', 'Computer Science']   \n",
       "1                         22              ['Computer Science']   \n",
       "2                         22              ['Computer Science']   \n",
       "\n",
       "            authorId_list_from_citing  ...  citationcount_from_cited  \\\n",
       "0           ['39986350', '145142172']  ...                       283   \n",
       "1  ['2327626', '1688531', '47197693']  ...                       283   \n",
       "2  ['2327626', '1688531', '47197693']  ...                       283   \n",
       "\n",
       "   fieldsofstudy_s2_from_cited  authorId_list_from_cited  \\\n",
       "0         ['Computer Science']  ['144545126', '1701637']   \n",
       "1         ['Computer Science']  ['144545126', '1701637']   \n",
       "2         ['Computer Science']  ['144545126', '1701637']   \n",
       "\n",
       "  fieldsofstudy_s2_from_cited_one fieldsofstudy_s2_from_citing_one team_size  \\\n",
       "0                Computer Science                         Business       2.0   \n",
       "1                Computer Science                 Computer Science       3.0   \n",
       "2                Computer Science                 Computer Science       3.0   \n",
       "\n",
       "  if_background  if_end_citation  corpusid  \\\n",
       "0           1.0              1.0   2019777   \n",
       "1           1.0              1.0   2019777   \n",
       "2           1.0              1.0   2019777   \n",
       "\n",
       "                                           sentences  \n",
       "0  ['\\nOptimal Space-Time Codes for the MIMO Ampl...  \n",
       "1  ['\\nOptimal Space-Time Codes for the MIMO Ampl...  \n",
       "2  ['\\nOptimal Space-Time Codes for the MIMO Ampl...  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_s2orc = pd.read_csv(\"/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_17_processed_merged_01_ims_added.tsv\", sep='\\t', nrows=10)\n",
    "df_s2orc = pd.read_csv(INPUT_FILE_LIST[0], sep='\\t', nrows=3)\n",
    "df_s2orc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d882851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citingcorpusid</th>\n",
       "      <th>citedcorpusid</th>\n",
       "      <th>context</th>\n",
       "      <th>context_count</th>\n",
       "      <th>intent</th>\n",
       "      <th>corpusid_from_citing</th>\n",
       "      <th>year_from_citing</th>\n",
       "      <th>citationcount_from_citing</th>\n",
       "      <th>fieldsofstudy_s2_from_citing</th>\n",
       "      <th>authorId_list_from_citing</th>\n",
       "      <th>...</th>\n",
       "      <th>authorId_list_from_cited</th>\n",
       "      <th>fieldsofstudy_s2_from_cited_one</th>\n",
       "      <th>fieldsofstudy_s2_from_citing_one</th>\n",
       "      <th>team_size</th>\n",
       "      <th>if_background</th>\n",
       "      <th>if_end_citation</th>\n",
       "      <th>is_selfcited</th>\n",
       "      <th>corpusid</th>\n",
       "      <th>sentences</th>\n",
       "      <th>similarity_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3458338</td>\n",
       "      <td>15236632.0</td>\n",
       "      <td>difficile causes over 500,000 infections per y...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>3458338.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>83</td>\n",
       "      <td>['Biology']</td>\n",
       "      <td>['5505204', '2804091', '5228121']</td>\n",
       "      <td>...</td>\n",
       "      <td>['6646092', '3464612']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Biology</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15236632</td>\n",
       "      <td>[\"\\nBurden of Clostridium difficile on the Hea...</td>\n",
       "      <td>[3.379587173461914, 1.333282232284546, 3.20222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3458338</td>\n",
       "      <td>15236632.0</td>\n",
       "      <td>C. difficile causes over 500,000 infections pe...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>3458338.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>83</td>\n",
       "      <td>['Biology']</td>\n",
       "      <td>['5505204', '2804091', '5228121']</td>\n",
       "      <td>...</td>\n",
       "      <td>['6646092', '3464612']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Biology</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15236632</td>\n",
       "      <td>[\"\\nBurden of Clostridium difficile on the Hea...</td>\n",
       "      <td>[3.4893946647644043, 1.223365306854248, 3.3126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11008261</td>\n",
       "      <td>15236632.0</td>\n",
       "      <td>8 billion per year in US acute-care facilities...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>11008261.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>54</td>\n",
       "      <td>['Medicine', 'Biology']</td>\n",
       "      <td>['1685489', '1399276983', '5080581', '14420245...</td>\n",
       "      <td>...</td>\n",
       "      <td>['6646092', '3464612']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15236632</td>\n",
       "      <td>[\"\\nBurden of Clostridium difficile on the Hea...</td>\n",
       "      <td>[2.6290435791015625, 1.4385323524475098, 2.486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3582207</td>\n",
       "      <td>15236632.0</td>\n",
       "      <td>8 billion dollars for acute care facilities al...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>3582207.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>40</td>\n",
       "      <td>['Medicine', 'Biology']</td>\n",
       "      <td>['31447259', '2109032396']</td>\n",
       "      <td>...</td>\n",
       "      <td>['6646092', '3464612']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15236632</td>\n",
       "      <td>[\"\\nBurden of Clostridium difficile on the Hea...</td>\n",
       "      <td>[2.389805793762207, 1.2772936820983887, 2.2773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22718940</td>\n",
       "      <td>15236632.0</td>\n",
       "      <td>8 billion per year in healthcare costs[2-5] .</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>22718940.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>100</td>\n",
       "      <td>['Biology', 'Medicine']</td>\n",
       "      <td>['33977517', '5958481']</td>\n",
       "      <td>...</td>\n",
       "      <td>['6646092', '3464612']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Biology</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>15236632</td>\n",
       "      <td>[\"\\nBurden of Clostridium difficile on the Hea...</td>\n",
       "      <td>[2.677427291870117, 1.1969443559646606, 2.1144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18500110</td>\n",
       "      <td>43861.0</td>\n",
       "      <td>Variations in “normal” DNA methylation are cor...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>18500110.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>43</td>\n",
       "      <td>['Biology', 'Chemistry']</td>\n",
       "      <td>['4638981', '6061038', '6685701', '28017081', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>['145266481', '48855488', '46269863', '3930915...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43861</td>\n",
       "      <td>['\\nEpigenetic regulation of PPARGC1A in human...</td>\n",
       "      <td>[2.804353713989258, 1.9161590337753296, 1.3340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>208253176</td>\n",
       "      <td>43861.0</td>\n",
       "      <td>In pancreatic β-cells of patients with type 2 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>208253176.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>50</td>\n",
       "      <td>['Medicine', 'Biology']</td>\n",
       "      <td>['48106504']</td>\n",
       "      <td>...</td>\n",
       "      <td>['145266481', '48855488', '46269863', '3930915...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43861</td>\n",
       "      <td>['\\nEpigenetic regulation of PPARGC1A in human...</td>\n",
       "      <td>[3.6736152172088623, 3.000868320465088, 1.7631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>221342868</td>\n",
       "      <td>43861.0</td>\n",
       "      <td>Ling et al. reported that the DNA methylation ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>221342868.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>['Biology', 'Medicine']</td>\n",
       "      <td>['2152477901', '2153466196', '2060047251', '15...</td>\n",
       "      <td>...</td>\n",
       "      <td>['145266481', '48855488', '46269863', '3930915...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43861</td>\n",
       "      <td>['\\nEpigenetic regulation of PPARGC1A in human...</td>\n",
       "      <td>[4.087973594665527, 2.9462785720825195, 1.8243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>221342868</td>\n",
       "      <td>43861.0</td>\n",
       "      <td>reported that the DNA methylation of the PPARG...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>221342868.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>['Biology', 'Medicine']</td>\n",
       "      <td>['2152477901', '2153466196', '2060047251', '15...</td>\n",
       "      <td>...</td>\n",
       "      <td>['145266481', '48855488', '46269863', '3930915...</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43861</td>\n",
       "      <td>['\\nEpigenetic regulation of PPARGC1A in human...</td>\n",
       "      <td>[4.132634162902832, 2.9574837684631348, 1.8643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1544704</td>\n",
       "      <td>6098524.0</td>\n",
       "      <td>A systematic review investigating PA/ST among ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['background']</td>\n",
       "      <td>1544704.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>['Medicine']</td>\n",
       "      <td>['35198780', '48308692']</td>\n",
       "      <td>...</td>\n",
       "      <td>['52014100', '48308692']</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6098524</td>\n",
       "      <td>['\\nPhysical activity among South Asian women:...</td>\n",
       "      <td>[2.5680556297302246, 1.9096953868865967, 1.744...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    citingcorpusid  citedcorpusid  \\\n",
       "0          3458338     15236632.0   \n",
       "1          3458338     15236632.0   \n",
       "2         11008261     15236632.0   \n",
       "3          3582207     15236632.0   \n",
       "4         22718940     15236632.0   \n",
       "..             ...            ...   \n",
       "95        18500110        43861.0   \n",
       "96       208253176        43861.0   \n",
       "97       221342868        43861.0   \n",
       "98       221342868        43861.0   \n",
       "99         1544704      6098524.0   \n",
       "\n",
       "                                              context  context_count  \\\n",
       "0   difficile causes over 500,000 infections per y...            2.0   \n",
       "1   C. difficile causes over 500,000 infections pe...            2.0   \n",
       "2   8 billion per year in US acute-care facilities...            1.0   \n",
       "3   8 billion dollars for acute care facilities al...            1.0   \n",
       "4       8 billion per year in healthcare costs[2-5] .            1.0   \n",
       "..                                                ...            ...   \n",
       "95  Variations in “normal” DNA methylation are cor...            1.0   \n",
       "96  In pancreatic β-cells of patients with type 2 ...            1.0   \n",
       "97  Ling et al. reported that the DNA methylation ...            2.0   \n",
       "98  reported that the DNA methylation of the PPARG...            2.0   \n",
       "99  A systematic review investigating PA/ST among ...            5.0   \n",
       "\n",
       "            intent  corpusid_from_citing  year_from_citing  \\\n",
       "0   ['background']             3458338.0              2018   \n",
       "1   ['background']             3458338.0              2018   \n",
       "2   ['background']            11008261.0              2014   \n",
       "3   ['background']             3582207.0              2017   \n",
       "4   ['background']            22718940.0              2016   \n",
       "..             ...                   ...               ...   \n",
       "95  ['background']            18500110.0              2014   \n",
       "96  ['background']           208253176.0              2014   \n",
       "97  ['background']           221342868.0              2020   \n",
       "98  ['background']           221342868.0              2020   \n",
       "99  ['background']             1544704.0              2014   \n",
       "\n",
       "    citationcount_from_citing fieldsofstudy_s2_from_citing  \\\n",
       "0                          83                  ['Biology']   \n",
       "1                          83                  ['Biology']   \n",
       "2                          54      ['Medicine', 'Biology']   \n",
       "3                          40      ['Medicine', 'Biology']   \n",
       "4                         100      ['Biology', 'Medicine']   \n",
       "..                        ...                          ...   \n",
       "95                         43     ['Biology', 'Chemistry']   \n",
       "96                         50      ['Medicine', 'Biology']   \n",
       "97                         10      ['Biology', 'Medicine']   \n",
       "98                         10      ['Biology', 'Medicine']   \n",
       "99                         11                 ['Medicine']   \n",
       "\n",
       "                            authorId_list_from_citing  ...  \\\n",
       "0                   ['5505204', '2804091', '5228121']  ...   \n",
       "1                   ['5505204', '2804091', '5228121']  ...   \n",
       "2   ['1685489', '1399276983', '5080581', '14420245...  ...   \n",
       "3                          ['31447259', '2109032396']  ...   \n",
       "4                             ['33977517', '5958481']  ...   \n",
       "..                                                ...  ...   \n",
       "95  ['4638981', '6061038', '6685701', '28017081', ...  ...   \n",
       "96                                       ['48106504']  ...   \n",
       "97  ['2152477901', '2153466196', '2060047251', '15...  ...   \n",
       "98  ['2152477901', '2153466196', '2060047251', '15...  ...   \n",
       "99                           ['35198780', '48308692']  ...   \n",
       "\n",
       "                             authorId_list_from_cited  \\\n",
       "0                              ['6646092', '3464612']   \n",
       "1                              ['6646092', '3464612']   \n",
       "2                              ['6646092', '3464612']   \n",
       "3                              ['6646092', '3464612']   \n",
       "4                              ['6646092', '3464612']   \n",
       "..                                                ...   \n",
       "95  ['145266481', '48855488', '46269863', '3930915...   \n",
       "96  ['145266481', '48855488', '46269863', '3930915...   \n",
       "97  ['145266481', '48855488', '46269863', '3930915...   \n",
       "98  ['145266481', '48855488', '46269863', '3930915...   \n",
       "99                           ['52014100', '48308692']   \n",
       "\n",
       "    fieldsofstudy_s2_from_cited_one  fieldsofstudy_s2_from_citing_one  \\\n",
       "0                          Medicine                           Biology   \n",
       "1                          Medicine                           Biology   \n",
       "2                          Medicine                          Medicine   \n",
       "3                          Medicine                          Medicine   \n",
       "4                          Medicine                           Biology   \n",
       "..                              ...                               ...   \n",
       "95                          Biology                           Biology   \n",
       "96                          Biology                          Medicine   \n",
       "97                          Biology                           Biology   \n",
       "98                          Biology                           Biology   \n",
       "99                         Medicine                          Medicine   \n",
       "\n",
       "   team_size if_background if_end_citation is_selfcited  corpusid  \\\n",
       "0        3.0           1.0             1.0         True  15236632   \n",
       "1        3.0           1.0             1.0         True  15236632   \n",
       "2       11.0           1.0             1.0         True  15236632   \n",
       "3        2.0           1.0             1.0         True  15236632   \n",
       "4        2.0           1.0             1.0         True  15236632   \n",
       "..       ...           ...             ...          ...       ...   \n",
       "95       5.0           1.0             1.0         True     43861   \n",
       "96       1.0           1.0             1.0         True     43861   \n",
       "97       4.0           1.0             1.0         True     43861   \n",
       "98       4.0           1.0             1.0         True     43861   \n",
       "99       2.0           1.0             1.0         True   6098524   \n",
       "\n",
       "                                            sentences  \\\n",
       "0   [\"\\nBurden of Clostridium difficile on the Hea...   \n",
       "1   [\"\\nBurden of Clostridium difficile on the Hea...   \n",
       "2   [\"\\nBurden of Clostridium difficile on the Hea...   \n",
       "3   [\"\\nBurden of Clostridium difficile on the Hea...   \n",
       "4   [\"\\nBurden of Clostridium difficile on the Hea...   \n",
       "..                                                ...   \n",
       "95  ['\\nEpigenetic regulation of PPARGC1A in human...   \n",
       "96  ['\\nEpigenetic regulation of PPARGC1A in human...   \n",
       "97  ['\\nEpigenetic regulation of PPARGC1A in human...   \n",
       "98  ['\\nEpigenetic regulation of PPARGC1A in human...   \n",
       "99  ['\\nPhysical activity among South Asian women:...   \n",
       "\n",
       "                                      similarity_list  \n",
       "0   [3.379587173461914, 1.333282232284546, 3.20222...  \n",
       "1   [3.4893946647644043, 1.223365306854248, 3.3126...  \n",
       "2   [2.6290435791015625, 1.4385323524475098, 2.486...  \n",
       "3   [2.389805793762207, 1.2772936820983887, 2.2773...  \n",
       "4   [2.677427291870117, 1.1969443559646606, 2.1144...  \n",
       "..                                                ...  \n",
       "95  [2.804353713989258, 1.9161590337753296, 1.3340...  \n",
       "96  [3.6736152172088623, 3.000868320465088, 1.7631...  \n",
       "97  [4.087973594665527, 2.9462785720825195, 1.8243...  \n",
       "98  [4.132634162902832, 2.9574837684631348, 1.8643...  \n",
       "99  [2.5680556297302246, 1.9096953868865967, 1.744...  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s2orc = pd.read_csv(\"/shared/3/projects/citation-context/s2orc/s2orc_merge/s2orc_17_processed_merged_01_ims_added.tsv\", sep='\\t', nrows=100)\n",
    "df_s2orc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baac6128",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sci_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msci_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SciParser\n\u001b[1;32m      2\u001b[0m sciparser \u001b[38;5;241m=\u001b[39m SciParser(cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sci_parser'"
     ]
    }
   ],
   "source": [
    "from sci_parser import SciParser\n",
    "sciparser = SciParser(cuda = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadde122",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [\"Climate change is a formidable societal challenge that requires urgent attention.\",\n",
    "              \"Finally, we present a research agenda and discuss the implications of our findings.\",\n",
    "              \"we provide examples of future research topics corresponding to each aspect of strategy solution mentioned in the integrative taxonomy of solutions for climate change.\",\n",
    "              \"Overall, the exemplar ideas provided in Table 1, Table 2, Table 3, Table 4 could form the foundation for selecting research topics for future studies on organizational strategy to resolve the climate change social challenge, in particular, and social dilemmas in general.\",\n",
    "              \"As tackling ecological problems needs a broader perspective in which collective and behavioral responses from individuals, organizations, and social groups become central, we approach the climate change challenge as a social dilemma. Therefore, building on research on social dilemmas and associated taxonomies of solutions, we develop an integrative taxonomy of strategic solutions for the climate change social dilemma. Next, we look at the climate action recommendations of leading organizations that grew out of the League of Nations – the United Nations, the World Economic Forum, the World Bank, the World Business Council for Sustainable Development, and the Intergovernmental Panel on Climate Change. Then, using our taxonomy, we systematically review management research on strategies for resolving the climate change social dilemma. Finally, we present a research agenda and discuss the implications of our findings.\"]\n",
    "sciparser.predict(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9dc86e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hongcc/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# If haven't downloaded the punkt package, should do it once\n",
    "nltk.download('punkt')\n",
    "\n",
    "'''\n",
    "alternative way: same\n",
    "'''\n",
    "# def split_sentences(text):\n",
    "#     sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "#     sentences = sentence_detector.tokenize(text.strip())\n",
    "#     return sentences\n",
    "\n",
    "'''\n",
    "alternative way: worse performance\n",
    "'''\n",
    "# def split_sentences(text):\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "#     # nlp = spacy.load('en_core_web_trf')\n",
    "#     doc = nlp(text)\n",
    "#     return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "def split_sentences(text):\n",
    "    return nltk.tokenize.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fbfe31eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a sentence.', 'So is this.', 'And this one too!']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "text = \"This is a sentence. So is this. And this one too!\"\n",
    "# text = full_text_list[0]\n",
    "sentences = split_sentences(text)\n",
    "# for sentence in sentences:\n",
    "#     print(sentence)\n",
    "\n",
    "sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8eed71",
   "metadata": {},
   "source": [
    "# IMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0543f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from typing import Optional, AnyStr, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimilarityEstimator(object):\n",
    "    \"\"\"\n",
    "    Estimator of information matching score (IMS) between two scientific sentences\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name_or_path: Optional[AnyStr] = 'copenlu/spiced',\n",
    "            device: Optional[AnyStr] = None,\n",
    "            use_auth_token: Optional[bool] = False,\n",
    "            cache_folder: Optional[AnyStr] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model_name_or_path: If it is a filepath on disc, it loads the model from that path. If it is not a path, it first tries to download a pre-trained SentenceTransformer model. If that fails, tries to construct a model from Huggingface models repository with that name. Defaults to the best model from Wright et al. 2022.\n",
    "        :param device: Device (like ‘cuda’ / ‘cpu’) that should be used for computation. If None, checks if a GPU can be used.\n",
    "        :param use_auth_token: HuggingFace authentication token to download private models.\n",
    "        :param cache_folder: Path to store models\n",
    "        \"\"\"\n",
    "        self.model_name_or_path = model_name_or_path\n",
    "        self.device = device\n",
    "        self.use_auth_token = use_auth_token\n",
    "        self.cache_folder = cache_folder\n",
    "\n",
    "        self.model = SentenceTransformer(\n",
    "            model_name_or_path=model_name_or_path,\n",
    "            device=device,\n",
    "            use_auth_token=use_auth_token,\n",
    "            cache_folder=cache_folder\n",
    "        )\n",
    "\n",
    "    def estimate_ims(\n",
    "            self,\n",
    "            a: List[AnyStr],\n",
    "            b: List[AnyStr]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Estimate the information matching score between all sentences in 'a' and all sentences in 'b'. Score will a scalar between 1 and 5, where 1 means no information similarity and 5 means the information is exactly the same between the two sentences.\n",
    "        :param a: A list of sentences\n",
    "        :param b: Second list of sentences\n",
    "        :return: A matrix S of size $N$x$M$ where $N$ is the length of list $a$, $M$ is the length of list $b$, and entry $S_{ij}$ is the information matching score between sentence $a_{i}$ and $b_{j}$\n",
    "        \"\"\"\n",
    "        sentence1_embedding = self.model.encode(a)\n",
    "        sentence2_embedding = self.model.encode(b)\n",
    "        S = (util.cos_sim(sentence1_embedding, sentence2_embedding).clip(min=0, max=1) * 4) + 1\n",
    "\n",
    "        return S.detach().numpy()\n",
    "\n",
    "\n",
    "    def estimate_ims_array(\n",
    "            self,\n",
    "            a: List[AnyStr],\n",
    "            b: List[AnyStr]\n",
    "    ) -> List:\n",
    "        \"\"\"\n",
    "        Estimate the information matching score between each sentence in $a$ and its corresponding $b$ (i.e. $a_{i}$ and $b_{i}$). Score will a scalar between 1 and 5, where 1 means no information similarity and 5 means the information is exactly the same between the two sentences.\n",
    "        :param a: A list of sentences\n",
    "        :param b: Second list of sentences of the same size as $a$\n",
    "        :return: A list $s$ of size $N$ where $N$ is the length of both list $a$ and list $b$ and entry $s_{i}$ is the information matching score between $a_{i}$ and $b_{i}$\n",
    "        \"\"\"\n",
    "        assert len(a) == len(b), f\"len(a) != len(b), lists of sentences must be equal length. len(a) == {len(a)}, len(b) == {len(b)}\"\n",
    "        sentence1_embedding = self.model.encode(a)\n",
    "        sentence2_embedding = self.model.encode(b)\n",
    "        scores = F.cosine_similarity(torch.Tensor(sentence1_embedding), torch.Tensor(sentence2_embedding), dim=1).clip(\n",
    "            min=0).squeeze().cpu().numpy()\n",
    "        # Convert to range [1,5], assume anything below 0 is 0\n",
    "        s = (scores * 4) + 1\n",
    "\n",
    "        return s.tolist()\n",
    "\n",
    "    def estimate_ims_test(self, a: List[str], b: List[List[str]]) -> List[List[float]]:\n",
    "\n",
    "        \"\"\"\n",
    "        Estimate the information matching score between each sentence in 'a' and its corresponding list of sentences in 'b'. \n",
    "        Score will be a scalar between 1 and 5, where 1 means no information similarity and 5 means the information is \n",
    "        exactly the same between the two sentences.\n",
    "        \n",
    "        :param a: A list of sentences\n",
    "        :param b: A list where each element is a list of sentences\n",
    "        :return: A matrix S of size $N$x$100$ where $N$ is the length of list 'a' and entry $S_{ij}$ is the information \n",
    "                 matching score between sentence $a_i$ and the jth sentence in the ith list of 'b'.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Ensure the lengths of 'a' and 'b' match\n",
    "        assert len(a) == len(b), \"Lengths of input lists do not match!\"\n",
    "        \n",
    "        # Batch encode sentences from 'a'\n",
    "        a_embeddings = self.model.encode(a)\n",
    "        \n",
    "        # Batch encode lists from 'b'. Given that 'b' is a list of lists, this will \n",
    "        # flatten the results into a single long list of embeddings\n",
    "        b_embeddings = [self.model.encode(b_list) for b_list in b]\n",
    "        \n",
    "        # Initialize an empty list to store the similarity matrices\n",
    "        results = []\n",
    "\n",
    "        # Compute similarities for each sentence embedding against its corresponding list of embeddings\n",
    "        for a_embedding, b_list_embedding in zip(a_embeddings, b_embeddings):\n",
    "            similarities = util.cos_sim([a_embedding], b_list_embedding)\n",
    "            S = (similarities.clip(min=0, max=1) * 4) + 1\n",
    "            results.append(S.tolist()[0])  # Convert to list and append\n",
    "            \n",
    "        # Stack results to get a matrix of shape N x 100\n",
    "        # but the length of strings in each list can vary so is not a np array\n",
    "        # return np.vstack(results)\n",
    "        \n",
    "        return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b225b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01530099 -0.0771071  -0.01632301 ... -0.01830022  0.02702273\n",
      "   0.00416675]\n",
      " [ 0.03343391  0.00025768 -0.00955451 ... -0.03396272 -0.06403445\n",
      "   0.00123405]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('copenlu/spiced')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "febc3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SimilarityEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b06d78c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5644999, 2.4583426, 2.1688566]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.estimate_ims(\"aaaaaaa\", [\"hello worldaa\", \"worldaa\", \"not a worldaa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ad5d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.564499855041504,\n",
       "  1.4180845022201538,\n",
       "  2.4583425521850586,\n",
       "  2.168856620788574],\n",
       " [1.3977493047714233, 1.5280011892318726, 1.8924036026000977]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_list = estimator.estimate_ims_test([\"aaaaaaa\", \"b\"], [[\"hello worldaa\", \"d\",\"worldaa\", \"not a worldaa\"], [\"hello world\", \"world\", \"not a world\"]])\n",
    "test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6438c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.564499855041504, 1.4180845022201538, 2.4583425521850586, 2.168856620788574]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e81e0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.8284118175506592, 1.6058390140533447],\n",
       " [1.347927212715149, 1.4270029067993164]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_similarity_for_batch(single_strings, list_of_strings_batch):\n",
    "    # Note: We assume that estimate_ims can handle batches efficiently.\n",
    "    similarity_matrices = estimator.estimate_ims(single_strings, list_of_strings_batch)\n",
    "    return [matrix.flatten().tolist() for matrix in similarity_matrices]\n",
    "\n",
    "compute_similarity_for_batch([\"a\", \"b\"], [[\"hello worldaa\", \"worldaa\", \"not a worldaa\"], [\"hello world\", \"world\", \"not a world\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c979128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a                                                  b\n",
      "0  a  [hello worldaa, hello worldaa, worldaa, worlda...\n",
      "1  b           [hello world, world, world, not a world]\n",
      "2  c                  [hello world, world, not a world]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"a\":[\"a\", \"b\", \"c\"],\n",
    "    \"b\": [[\"hello worldaa\", \"hello worldaa\", \"worldaa\", \"worldaa\", \"not a worldaa\"], [\"hello world\", \"world\", \"world\", \"not a world\"], [\"hello world\", \"world\", \"not a world\"]]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2465821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebe02c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "955a6e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 2/2 [00:00<00:00,  9.75it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity_lists = []\n",
    "\n",
    "# Determine the number of batches\n",
    "num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "\n",
    "# Split the DataFrame into batches\n",
    "single_string_batches = np.array_split(df['a'].values, num_batches)\n",
    "list_of_strings_batches = np.array_split(df['b'].values, num_batches)\n",
    "\n",
    "for single_strings, list_of_strings in tqdm(zip(single_string_batches, list_of_strings_batches), total=num_batches, desc=\"Processing batches\"):\n",
    "    # Assuming the function compute_similarity_for_batch is defined somewhere\n",
    "    batch_similarity_lists = compute_similarity_for_batch(single_strings, list_of_strings)\n",
    "    similarity_lists.extend(batch_similarity_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "455d8774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['a', 'b'], dtype=object), array(['c'], dtype=object)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_string_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b2f669a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 3/3 [00:00<00:00,  5.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>similarity_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>[hello worldaa, hello worldaa, worldaa, worlda...</td>\n",
       "      <td>[1.9064209461212158, 1.9064209461212158, 2.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>[hello world, world, world, not a world]</td>\n",
       "      <td>[1.397749423980713, 1.5280015468597412, 1.5280...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>[hello world, world, not a world]</td>\n",
       "      <td>[1.404463291168213, 1.5151492357254028, 1.7486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a                                                  b   \n",
       "0  a  [hello worldaa, hello worldaa, worldaa, worlda...  \\\n",
       "1  b           [hello world, world, world, not a world]   \n",
       "2  c                  [hello world, world, not a world]   \n",
       "\n",
       "                                     similarity_list  \n",
       "0  [1.9064209461212158, 1.9064209461212158, 2.080...  \n",
       "1  [1.397749423980713, 1.5280015468597412, 1.5280...  \n",
       "2  [1.404463291168213, 1.5151492357254028, 1.7486...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def compute_similarity_for_batch(single_strings, list_of_strings_batch):\n",
    "    # Note: We assume that estimate_ims can handle batches efficiently.\n",
    "    similarity_lists = estimator.estimate_ims_test(single_strings, list_of_strings_batch)\n",
    "    return similarity_lists\n",
    "\n",
    "def compute_similarity_for_dataframe(df, batch_size=250):\n",
    "    similarity_lists = []\n",
    "\n",
    "    # Determine the number of batches\n",
    "    num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
    "\n",
    "    # Split the DataFrame into batches\n",
    "    single_string_batches = np.array_split(df['a'].values, num_batches)\n",
    "    list_of_strings_batches = np.array_split(df['b'].values, num_batches)\n",
    "    \n",
    "    for single_strings, list_of_strings in tqdm(zip(single_string_batches, list_of_strings_batches), total=num_batches, desc=\"Processing batches\"):\n",
    "        # Assuming the function compute_similarity_for_batch is defined somewhere\n",
    "        batch_similarity_lists = compute_similarity_for_batch(single_strings, list_of_strings)\n",
    "        similarity_lists.extend(batch_similarity_lists)\n",
    "\n",
    "    return similarity_lists\n",
    "\n",
    "# Load the data\n",
    "df['similarity_list'] = compute_similarity_for_dataframe(df, batch_size=1)\n",
    "\n",
    "df\n",
    "# Save the result.\n",
    "# df.to_csv('output_with_similarity_lists.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2cc05263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9064209461212158,\n",
       " 1.9064209461212158,\n",
       " 2.080775260925293,\n",
       " 2.080775260925293,\n",
       " 2.6484429836273193]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"similarity_list\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a93ab206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.397749423980713, 1.5280015468597412, 1.5280015468597412, 1.8924040794372559]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"similarity_list\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "838b2876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.404463291168213, 1.5151492357254028, 1.7486413717269897]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"similarity_list\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937159a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
